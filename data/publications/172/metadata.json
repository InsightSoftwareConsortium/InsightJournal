{
  "publication": {
    "abstract": "This document describes work-in-progress for refactoring ITK\u2019s registration methods to exploit the parallel, computation power of multi-processor, shared-memory systems. Refactoring includes making the methods multi-threaded as well as optimizing the algorithms. API backward compatibility is being maintained. Helper classes that solve common registration tasks are also being developed.\r\n\r\n\r\nThe refactoring has reduced computation times by factors of 2 to 200 for metrics, interpolators, and transforms computed on multi-processor systems. Extensive sets of tests are being developed to further test operation and backward compatibility.",
    "articles": [
      null,
      "bafybeib3h24tslnkhgswrwibw6d6h5wmbcgbgazlwq72rzhywx2ibnzai4",
      "bafybeihrwfiwnq7x2wblnq3edffoygwemjka75qjyhmuzmawztugziye6a"
    ],
    "authors": [
      {
        "author_fullname": "Aylward, Stephen",
        "author_place": 1,
        "persona_email": "stephen.aylward@kitware.com",
        "persona_firstname": "Stephen",
        "persona_id": 1,
        "persona_lastname": "Aylward"
      },
      {
        "author_fullname": "Jomier, Julien",
        "author_place": 2,
        "persona_email": "julien@jomier.com",
        "persona_firstname": "Julien",
        "persona_id": 3,
        "persona_lastname": "Jomier"
      },
      {
        "author_fullname": "Barre, Sebastien",
        "author_place": 3,
        "persona_email": "sebastien.barre@kitware.com",
        "persona_firstname": "Sebastien",
        "persona_id": 589,
        "persona_lastname": "BARRE"
      },
      {
        "author_fullname": "Davis, Brad",
        "author_place": 4,
        "persona_email": "brad.davis@kitware.com",
        "persona_firstname": "Brad",
        "persona_id": 596,
        "persona_lastname": "Davis"
      },
      {
        "author_fullname": "Ibanez, Luis",
        "author_place": 5,
        "persona_email": "luis.ibanez@kitware.com",
        "persona_firstname": "Luis",
        "persona_id": 4,
        "persona_lastname": "Ibanez"
      }
    ],
    "categories": [
      "Deformable registration",
      "Groupwise registration",
      "Image pyramids",
      "Multi-modality registration",
      "Registration metrics",
      "Registration optimizers",
      "Transforms"
    ],
    "comments": [],
    "date_submitted": "2007-07-16T05:46:53Z",
    "journals": [
      {
        "journal_id": 3,
        "journal_name": "The Insight Journal"
      }
    ],
    "license": "You are licensing your work to Kitware Inc. under the\nCreative Commons Attribution License Version 3.0.\n\nKitware Inc. agrees to the following:\n\nKitware is free\n * to copy, distribute, display, and perform the work\n * to make derivative works\n * to make commercial use of the work\n\nUnder the following conditions:\n\\\"by Attribution\\\" - Kitware must attribute the work in the manner specified by the author or licensor.\n\n * For any reuse or distribution, they must make clear to others the license terms of this work.\n * Any of these conditions can be waived if they get permission from the copyright holder.\n\nYour fair use and other rights are in no way affected by the above.\n\nThis is a human-readable summary of the Legal Code (the full license) available at\nhttp://creativecommons.org/licenses/by/3.0/legalcode",
    "publication_id": 172,
    "reviews": [
      {
        "author": {
          "author_email": "rupert.brooks@gmail.com",
          "author_firstname": "Rupert",
          "author_id": 171,
          "author_lastname": "Brooks"
        },
        "content": "<strong>Summary:</strong><br />The authors propose to speed up the implementation of ITKs registration framework both through code optmizations and multithreading. ITKs registration framework is - or perhaps I should say was - regrettably slow. This paper is an excellent and much needed contribution. <br /><br />If imitation is the sincerest form of flattery, the authors should know that I am planning to reimplement much of my own work using the ideas and framework presented here.<br /><br /><strong>Evidence:</strong><br />The majority of the evidence presented is in the form of timing comparisons on two machines. Unfortunately, there are several different speed up methods at work here. It is difficult to discern from the evidence, which code changes are more important. In my reproduction of the work (see below) I noted that there are speedups of both the metric evaluations, and the metric initialization. This is of course good, but this might merit separate analysis.<br /><br /><strong>Open Science:</strong><br />The work adheres to the principles of open science. However - the work was somewhat difficult to reproduce. Recently the code was added to the ITK CVS, which made access to it much easier. However, it was added in such a way that an ITKCVS build seems to either use these classes, or the original versions, but not both. At least, it appears this way - in all honesty i did not try to build them from the Review directory, but came up with my own way. Details follow below. <br /><br /><strong>Reproducibility:</strong><br />I got the code working in nearly its original form. Very significant speedup was immediately apparent, plus of course the new capability of multithreading. As this is a new framework for (mainly) the ITK registration metrics, i implemented some of my own work in this framework. This was not possible to do easily from the document - it was only possible after carefully reading the code.<br /><br />A careful testing approach is essential for any large code optimization project like this. The approach described in the paper seems good. However, I did not reproduce it. The current set up in the ITK CVS seems to preclude testing the old against the new versions of metrics unless one is willing to build two concurrent ITK installs. Even then, how one could write a single program to run one metric, then the other and compare their output was not obvious. I did it my own way see below.<br /><br /><strong>Use of Open Source Software / Open Source Contributions:</strong><br />It is a contribution to the open source ITK project.<br /><br /><strong>Code Quality:</strong><br />The code is of high quality. However, there are three design criticisms that i might make<br />1. A not insignificant part of the speed is due to using memset instead of the Fill() methods. Perhaps the Fill methods should be recoded to use memset instead? Then the speed benefit would appear everywhere that uses them.<br /><br />2. The code for the threaded GetValue and GetValueAndDerivative methods is complex and highly repetitive. As we all know, repetitive code is hard to maintain. I think that the repetition could be reduced somewhat. In particular, i found it possible to compress both the Transform point methods into one. I found other ways of reducing the amount of repeated code in my re-implementation by using a recursive including scheme, but this did make it a bit more difficult to understand. <br /><br />3. The caching of the bspline parameters does give a significant speedup, but at the cost of a MASSIVE use of memory. For any interesting size 3D image, and even many 2D images, it is completely impossible to run this on a 32-bit system. I think there should be a switch to turn this on or off. Yes it runs slower, but its still useful to run it on 32-bit systems on medium size images.<br /><br />Requests for additional information from authors:<br />I think that additional documentation is needed. Not all the modified classes are described, or even listed, in the text. <br />In particular, i found the way the multithreading is actually implemented, and what a user must implement to reproduce their own metric, would benefit from a written thorough explanation. I had to read the code - very carefully - to figure it out.<br /><br />It would also be interesting to have a list of what is different about all the optimized classes. Some independent testing might be valuable. For example, how much of the speed up is due to the interpolator, and how much to the metric? What is the optimized resample filter, it is not discussed in the text.<br /><br />It seems to me that the efficiency of these methods is highly reliant on inlining, especially of the ThreadProcessSample function. This would be interesting to explore. If inlineing is not vital, function pointers could be used, which could simplify the code, i think. On the other hand, if inlining is important, perhaps the transform point method (also called for every pixel) could be inlined. <br /><br />I was curious about the authors thoughts of existing shared memory parallelization methods, in particular openMP, as a way of getting quick multithread gains for low coding effort. This was more a vague thought, than a specific request. Clearly many of the compilers on which ITK is built do not support openMP, so it may not have universal applicability.<br /><br /><strong>Additional Comments:</strong><br /><br /><em>How I reproduced (some of) the work.</em><br /><br />I was using the version in the ITK CVS as of Feb 6, 2008. The rest of the code besides the review directory was ITK 3.4. The optimized classes are intended to replace the nonoptimized classes of the same name - therefore building both alongside each other is difficult. I first renamed all the optimized classes to have the prefix &quot;opt&quot; on their names. I then made the OptImageToImageMetric a subclass of ImageToImageMetric - this way i could plug it into existing code.<br /><br />I trusted the optimized interpolators, so i just began using them directly.<br /><br />I evaluated the metrics a number of times with the old metric implementation, and the new metric implementation, and compared the results. The mean squares metric is numerically identical to the old one. The MI metric is numerically very similar, but not identical. Both optimized metrics are MUCH faster, running single threaded. This is not due to the interpolators - during this test both metrics were using the same interpolators. The metric code itself is significantly more efficient.<br /><br />Running multithreaded, contrary to what is described in the text, I actually found further performance increases (although not even close to linear) running more threads than cores. Specifically 3 threads on a two core machine was noticably better than two. This was a Windows XP 32bit machine, compiler Visual C++ 2003. Its probably some quirk of windows.<br /><br />I did not evaluate the oriented image gradient fix - i have my own way of doing this, discussed elsewhere.<br /><br />I did not evaluate the optimized resample image filter.<br /><br />As a further evaluation of the work, I reimplemented one of my own metrics copying most of the ideas from this framework. I found that it was not too difficult to do, but does require a careful reading of the code - more documentation would have been helpful. The study of the code probably took me a days work. The implementation about 4 hours, and theres still a bug or two to track down. Nevertheless, i conclude that the framework is usable and general and strikes a reasonable balance between efficiency and intelligibility. As mentioned, I did find that the code might be difficult to maintain, due to repetition.<br /><br /><em>Things that may be bugs or errors:</em><br /><br />In the paper (p. 4) it says that the base itkTransform class was modified for thread safety. However, in the ITK CVS Review versions, there is no modified version of itkTransformBase. Furthermore, the classes seem to achieve thread safety by making multiple copies of the transform.<br />------<br />In Figure three, supposedly the old method is being compared to the new method. In the text it is claimed the new method is 6 times faster when run single threaded (probably true, based on my experience). However, the graph starts at 1. I dont think it graphs the right thing.<br />-------<br />in itkOptImageToImageMetric.txx<br /><br /> // If user provided a mask over the Moving image<br /> if ( m_MovingImageMask )<br /> {<br /> // Check if mapped point is within the support region of the moving image<br /> // mask<br /> sampleOk = m_MovingImageMask-&gt;IsInside( mappedPoint );<br /> }<br /> else<br /> {<br /> // Check if mapped point inside image buffer<br /> sampleOk = m_Interpolator-&gt;IsInsideBuffer( mappedPoint );<br /> }<br /> <br />I think that being inside the moving image mask does not guarantee that the point is inside the valid region of the moving image. I think both tests should be done.<br />-------<br />There is a minor inconsistency in that the stub for ThreadPostProcess is placed in the header, and the stubs for the other two are in the .txx<br />-------<br /><br /> <br /> ",
        "date": "02-18-2008",
        "review_id": 644
      },
      {
        "author": {
          "author_email": "holmes.david3@mayo.edu",
          "author_firstname": "David",
          "author_id": 20,
          "author_lastname": "Holmes"
        },
        "content": "<p><strong>Summary:</strong><br />The authors describe the optimization of the ITK registration framework for multi-processor systems.&nbsp; This includes some code optimization, making everything thread-safe, and threading several of the processing steps.&nbsp; The authors are targeting various transforms, metrics, interpolators, and solvers.</p><p><strong>Hypothesis:</strong><br />The hypothesis is that multi-threading will improve the computational performance of the ITK registration code.</p><p><br /><strong>Evidence:</strong><br />The authors have implemented and tested the code on several platforms.&nbsp; They present the results for two of the systems that they ran on.&nbsp; The results are consistent with expectations.<br /><br /><strong>Open Science:</strong><br />In true ITK form, the work is completely open.<br /><br /><strong>Reproducibility:</strong><br />I have to admit that I have not had a chance to download and run the code.&nbsp;<br /><br /><strong>Use of Open Source Software:</strong><br />The method was implemented in ITK.&nbsp; There was some use of BWHITK which I would guess is also available if I went looking for it.&nbsp; Valgrind was used for profiling which is open.&nbsp; Unfortunately, neither vtune nor ltprof are open source.&nbsp;<br /><br /><strong>Open Source Contributions:</strong><br />Great contribution<br /><br /><strong>Code Quality:</strong><br />Not evaluated<br /><br /><strong>Applicability to other problems:</strong><br />Well, this is the first of my two little issues.&nbsp; It is not about the work, which is incredible valuable, but about the details of the paper.&nbsp; One of the most important contributions here is that the authors have expended the energy to optimize multi-threading across platforms.&nbsp; This is the most &quot;applicable&quot; component of the work.&nbsp; Unfortunately, there is only one paragraph on the optimization process in which the authors state &quot;certain changes and parameterizations could improve performance on one platform and degrade performance on others....&quot;&nbsp; There are no details about the difference by platform or proposed explanations why this is.&nbsp; If someone is looking to develop cross-platform code that is multi-threaded, they might look to this article and find it lacking in that detail.&nbsp; If this has been previously explained, then I would simply suggest including a reference.<br /><br /><strong>Suggestions for future work:</strong><br />Speed is one of the major issues with optimized software, and the authors have addressed this issue very well.&nbsp; The other issue -- which can be at direct odds with the speed -- is the use of memory.&nbsp; Algorithms which require large amounts of memory are either slower or require machines with gobs (sorry for the technical jargon) of memory -- like 128 GB.&nbsp; In addition, making thread-safe code will result in more memory usage.&nbsp; This issue has not been discussed; it will be valuable to run this same set of tests and report the memory usage as the threads go up.</p><p><br /><strong>Requests for additional information from authors:</strong><br />Only the in the two areas noted above.<br /><br /><strong>Additional Comments:</strong><br />Congratulations on moving in this direction.&nbsp; Optimization is such an important process to make usable software particularly given the magnitude of the problems in medical imaging.</p>",
        "date": "09-12-2007",
        "review_id": 566
      },
      {
        "author": {
          "author_email": "agouaillard@gmail.com",
          "author_firstname": "Alexandre",
          "author_id": 322,
          "author_lastname": "Gouaillard"
        },
        "content": "<p><strong>Summary:</strong><br /> this paper report the first results of a multithreaded implementation of the ITK registration framework. Dedicated metrics and test environment has been developed to compare the new implementation with the previous one on different plateforms, with different environments and depending on the number of thread used.<br /> <br /> <strong>Hypothesis:</strong><br /> * multicore/multi cpu are ubiquitous or about to be (85% of intel CPU are currently at least dual core).<br /> * using all the core/cpu should improve the performances<br /> * the improvment should happen across plateform and OSes.&nbsp;</p><p><strong>Evidence:</strong><br /> The speed comparison depending on the number of thread have been plotted and illustrate the gain. Example are multiple and show clearly that users will gain from using the new implementation, whatever filter/metric/oprtimizer they use in the registration framework and whatever plateform they are working on. That was the main target of the work, and we can say: Work well done!<br /> Note: It seems that part of the gain was made from code optimisation and not multihreading. <br /> </p><p>It seems that using more threads is interesting as long as the number of threads is not greater than the number of cores/CPU. If the number of thread is higher, we see the performance decrease. It would be nice to have the filters decide ow many thread they want to use automatically. It does not seems to be consistent enough across platforms or threading implementation to be able to do so. Another point not discussed on the paper but discussed intensively on the itk-develloper mailin glist is that it depends on the multithreading implementation: does the filter creates and destroy threads, or does it access a pool of shared threads? This question is under investigation.</p><p>One very interesting part of the work is the implementation of the cross-platform multithreading testing and benchmarking tool. Mixing BatchMake and CMake seems to provide good results. It would be interesting in the future to use this tool for other multithreading implementations (the Mesh part of ITK would be my first target, but I&#39;m kind of biased). The authors also experiment a lot with different profiling tools and timing tools, I think many users would be interested in knowing which tools they used (they mention valgrind, but I suppose they mean cachegrind), what kind of experiment they did and what ther conclusion were about the pros and the cons of each tools. That is outside the scope of this paper, but that would make a great wiki page. <br /> </p><p><strong>Open Science:</strong><br />In ITK spirit, the author provide the code under BSD and the IJ article under CC. The code should be integrated in ITK post 3.4 release. It must be noted that modification of this magnitude can not be integrated in ITK at once. The quality process, that insure that the code is stable on an almost daily basis prevent that from happening.&nbsp; </p><p><strong>Reproducibility:</strong><br /> Checking out an older version of ITK, i could compile it and run a basic test. The amount of work needed to reproduce the result was such that I did not even try. Teh current version does not compile, but it should be only a matter of weeks before it is available in the CVS version of ITK.<br /> <br /> <strong>Use of Open Source Software:</strong><br />ITK</p><p> <strong>Open Source Contributions:</strong><br />integration in ITK in progress.</p><p><strong>Code Quality:</strong><br />Master Luis checked it, it should be good. Test are provided. Along the main line of work , the authors took the time to profile the application and found many improvements, not only on speed, but also on combinaitions of filters/metrics/optimizers that had never been tested together before and happened not to work along well. I guess a complete matrix test using all the possible combinations is being developped right now. It should find a lot of potential bugs an improve the overall quality of the registration framework. Thank you for that. </p><p><strong>Applicability to other problems:</strong><br />the multithreading test framework could be reused for other part of ITK, or for any multithreaded code that use CMake, I guess.<br /> A little report on the timing and profiling tools would be of interest.<br /> <br /><br /> <strong>Suggestions for future work:</strong><br />* threading implementation and other issues are being investigated and (intensely) discussed right now.<br /> * better and more complete registration framework tests are being developed.<br /> </p><p>It would be interesting to have results on realy big cases (zebrafish datasets ...) to check if you really have much better improvement in this case as you are expecting. In that case, it would also make the thread pool model more interesting. </p><p>You report that threads and associated items (mutex) implementation on SunOS were especially slow, and I noticed that the SunOS machine used for your test were using sunOS 5.8. It so happen that the SUN threading library is known to be horribly slow, untill sun decided to completely rewrite it. The new library was shipped separatly one year after the release of sunOS 5.8, so your machine might not have it installed. With the current OpenSolaris (or the latest release of 5.10) you should have much better results. I was wondering, out of pure curiosity, what the results would be on one of their &quot;Niagara&quot; box which is optimized for multithreading operations.<br /> <br /><br /> <strong>Requests for additional information from authors:</strong><br />It&#39;s a work on progress. I wil ljust wait for the results. Everything is really interesting indeed.<strong><br /> </strong></p>",
        "date": "09-13-2007",
        "review_id": 570
      },
      {
        "author": {
          "author_email": "torsten@synapse.sri.com",
          "author_firstname": "Torsten",
          "author_id": 168,
          "author_lastname": "Rohlfing"
        },
        "content": "<p>As the paper itself is labeled &quot;work in progress&quot; in more than one place, I will write a review that I would also consider work in progress. I won&#39;t try to get all details right, I won&#39;t try hard to get things to work, and I won&#39;t try not to step on anybody&#39;s toes by sounding like a smartass. I&#39;ll save all these for later when both the paper and this review converge towards their final forms.</p><p><strong>Observations regarding the software:</strong></p><p> 1. I cannot build the software due to linker errors:</p><pre><p>Linking CXX executable ../../bin/AlignRigidAffine<br />CMakeFiles/AlignRigidAffine.dir/AlignRigidAffineTest.o: In function `main&#39;:<br />AlignRigidAffineTest.cxx:(.text+0x3487): undefined reference to `itk::Optimizer::SetScales(itk::Array const&amp;)&#39;<br />AlignRigidAffineTest.cxx:(.text+0x3843): undefined reference to `itk::Optimizer::SetScales(itk::Array const&amp;)&#39;</p><p>.... [ more errors ] ... </p></pre> <p>I am running Fedora 7 on x86_84 using gcc 4.1.2 and today&#39;s CVS checkout of ITK (August 31, 2007).</p><p><strong>Observations regarding the paper:</strong></p><p>1. The paper listed for citation [Rohlfing, 2003] in the paper is very likely the wrong one. The correct one should probably be T. Rohlfing and C. R. Maurer, Jr., &ldquo;Nonrigid image registration in shared-memory multiprocessor environments with application to brains, breasts, and bees,&rdquo; <em>IEEE Transactions on Information Technology in Biomedicine</em>, vol. 7, no. 1, pp. 16-25, 2003.</p><p><strong>Observations regarding the techniques: </strong></p><p>1. I am very concerned by the use of sparse image sampling in nonrigid registration. I do not trust probabilistic sampling schemes for local deformations, and I doubt it is necessary when the algorithm is otherwise optimized.</p><p>2. Without any consideration as to whether any of these can be easily implemented in the current framework, I would like to mention a number of optimizations that I have found very effective in my own code:</p><ol><li> Each control point of the B-spline transformation effects only a small neighborhood, and gradients can be computed using finite differences by only recomputing the metric contribution of that local region. This leads to computational performance increase of several orders of magnitude. Furthermore, all three degrees of freedom of the same control point (its x,y,z position) effect the same subvolume, so the &quot;baseline&quot; metric of the remaining, unaffected volume can be used three times. </li><li>The B-spline transformation can be computed very efficiently (50% faster) using a scanline algorithm. The control point grid is aligned with the reference image grid, so all pixels within one x image row share the same relative y and z coordinate in the control point grid row and plane. These relative positions are also invariant under changes of the control point positions, so they can be computed once when the transformation object is created. Moreover, all pixels within the same control point cell receive the same contributions from the B-spline basis functions in y and z. So two out of three nested sums in the B-spline formula can be precomputed for all pixels in a given cell. The same observations hold for computing analytical derivatives (e.g., for bending energy and Jacobian matrices).<br /></li><li>The affine pre-registration transformation can be included in the B-spline transformation by interpreting the B-spline output as the transformed vector, rather than as an offset vector. Then, the affine transformation can simply be applied to the control point positions.</li><li>It is not necessarily necessary to have each thread work on a separate copy of the B-spline transformation for finite difference gradient approximation. If local computation of the metric changes (see Item 2.1 above) is used, than degrees of freedom that affect control points separated by more than 4 steps in any direction are entirely independent of each other. One could, therefore, order the control points into a &quot;schedule&quot; in which the next control point is always at least 4 grid steps away from the previous. Such a schedule has a &quot;maximally safe concurrent computation range&quot; associated with it that specifies how many successive control points from the schedule can be moved without affecting one another&#39;s local neighborhoods. This is also the number of parallel threads that can work along the schedule concurrently using the same B-spline parameter array without interfering with each other. The advantage of this technique is that it avoids duplication of the (potentially large) array of B-spline parameters. The downside is that it doesn&#39;t scale as well to larger numbers of CPUs (more than about 3 actually in my experience), although scaling improves as the number of control points increases. I myself have abandoned this idea again, but I thought I&#39;d mention it.</li><li>The paper mentions the possibility of excluding &quot;background&quot; control points from optimization to reduce the number of degrees of freedom and increase performance. There are at least two difference ways to achieve this, and I wanted to comment on the two: the first is &quot;static&quot; in the sense that it analyzes the image data to determine image background (described in Rohlfing et al., MICCAI 2001), the second is more &quot;dynamic&quot; in that it looks at the full cost function gradient and deactivates the control points with low gradient contributions (this was done by Schnabel, Tanner, Rueckert around the same time, but I don&#39;t have the references handy right now). I used to think that the second way was better, because it is more directly related to the gradient, whereas the image background detection is a bit removed from the optimization process. After playing with both techniques, however, I concluded that the static image analysis is preferable (at least for me), especially for large problems (think: groupwise registration), because it does not require to ever compute the full cost function gradient using all degrees of freedom. In cases where the cost of the full gradient is prohibitive, you can still get away very well with the static image background detection in the images themselves. </li></ol><p><strong>Other observations:</strong></p><p> I will go and rummage through my code to check for any other optimizations I may have forgotten about.</p><p> Once I manage to build the new ITK tools, I will perform an direct comparison of my own B-spline with the new one to see how their performance compares. </p>",
        "date": "09-11-2007",
        "review_id": 540
      }
    ],
    "revisions": [
      {
        "article": null,
        "dapp": null,
        "dataset": null,
        "doi": null,
        "handle": "1926/566",
        "source_code": null,
        "source_code_git_ref": null
      }
    ],
    "source_code_git_repo": null,
    "submitted_by_author": {
      "author_email": "stephen.aylward@kitware.com",
      "author_firstname": "Stephen",
      "author_fullname": "Aylward, Stephen",
      "author_id": 1,
      "author_institution": "Kitware, Inc.",
      "author_lastname": "Aylward"
    },
    "tags": [
      "Threaded",
      "Registration",
      "Parallel",
      "ITK"
    ],
    "title": "Optimizing ITK\u2019s Registration Methods for Multi-processor, Shared-Memory Systems"
  }
}