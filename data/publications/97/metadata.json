{
  "publication": {
    "abstract": "The software requirements for computer-aided navigation tools in image-guided therapy are becoming increasingly complex as a result of new possibilities in imaging and tracking hardware, novel application areas and regulatory restrictions.\r\nA new software framework has been developed to meet the needs of emerging image-guided procedures and therapies that require multi-modal imaging and tracking. This framework accommodates dynamic data-structures, dynamic input and output interfaces for interventional devices, and dynamic visualization of data. Arbitrary, yet meaningful, connections can be established between these entities in order to implement customized applications that target specific clinical procedures. A series of demonstration applications have been developed in order to emphasize different aspects of the framework, and are presented here.",
    "authors": [
      {
        "author_fullname": "Hata, Nobuhiko",
        "author_place": 6,
        "persona_id": null
      },
      {
        "author_fullname": "Jolesz, Ferenc",
        "author_place": 7,
        "persona_id": null
      },
      {
        "author_fullname": "Samset, Eigil",
        "author_place": 1,
        "persona_email": "samset@bwh.harvard.edu",
        "persona_firstname": "Eigil",
        "persona_id": 447,
        "persona_lastname": "Samset"
      },
      {
        "author_fullname": "Hans, Arne",
        "author_place": 2,
        "persona_id": null
      },
      {
        "author_fullname": "von Spiczak, Jochen",
        "author_place": 3,
        "persona_id": null
      },
      {
        "author_fullname": "DiMaio, Simon",
        "author_place": 4,
        "persona_email": "simon.dimaio@intusurg.com",
        "persona_firstname": "Simon",
        "persona_id": 937,
        "persona_lastname": "Dimaio"
      },
      {
        "author_fullname": "Ellis, Randy",
        "author_place": 5,
        "persona_id": null
      }
    ],
    "categories": [],
    "comments": [],
    "date_submitted": "2006-06-30T20:32:40Z",
    "journals": [
      {
        "journal_id": 3,
        "journal_name": "The Insight Journal"
      }
    ],
    "license": "You are licensing your work to Kitware Inc. under the\nCreative Commons Attribution License Version 3.0.\n\nKitware Inc. agrees to the following:\n\nKitware is free\n * to copy, distribute, display, and perform the work\n * to make derivative works\n * to make commercial use of the work\n\nUnder the following conditions:\n\\\"by Attribution\\\" - Kitware must attribute the work in the manner specified by the author or licensor.\n\n * For any reuse or distribution, they must make clear to others the license terms of this work.\n * Any of these conditions can be waived if they get permission from the copyright holder.\n\nYour fair use and other rights are in no way affected by the above.\n\nThis is a human-readable summary of the Legal Code (the full license) available at\nhttp://creativecommons.org/licenses/by/3.0/legalcode",
    "publication_id": 97,
    "reviews": [
      {
        "author": {
          "author_email": "cheng@isis.georgetown.edu",
          "author_firstname": "Patrick",
          "author_id": 456,
          "author_lastname": "Cheng"
        },
        "content": "<b>Summary:</b>\r\nThis paper describes a framework for developing various IGT applications.\r\n \r\n<b>Hypothesis:</b>\r\nNon Applicable\r\n\r\n<b>Evidence:</b>\r\nThe author claimed that, \u00e2\u0080\u009c\u00e2\u0080\u00a6with the purpose of providing a safe, dynamic and extensible software framework for image-guided therapy in a novel operation facility called AMIGO\u00e2\u0080\u009d, however he didn\u00e2\u0080\u0099t provide further evidence on how this framework achieved these design goals. \r\n\r\n<b>Open Science:</b>\r\nThe seamless integration with Slicer gives this toolkit a good support for developing variety of applications for surgical guidance and therapy. Its intention to go open source will surely benefit the research community\r\n\r\n<b>Reproducibility:</b>\r\nThere is no source code published with this paper at this moment.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThis work has taken full advantage of existing open source software toolkits, such as Slicer, OpenTracker, GIHI, and ACE etc. \r\n\r\n<b>Open Source Contributions:</b>\r\nThe source code will be release under open source license. \r\nWill the example applications also be available for the public?\r\n\r\n<b>Code Quality:</b>\r\nNot applicable\r\n\r\n<b>Applicability to other problems:</b>\r\nSome interesting clinical applications have been shown in this paper developed using the framework. It shows that this framework is quite flexible and has a wide range of clinical applications.\r\n\r\n<b>Suggestions for future work:</b>\r\nHave you considered the synchronization issue between hardware devices and application? Difference hardware devices in the surgical guidance system have different response frequency. There is also latency issue when communicating through the network. When integrating the information from difference sources together in the surgical scene, you need to be very careful about the accuracy of the information you are presenting to the surgeon. \r\n\r\n<b>Requests for additional information from authors:</b>\r\nNone.\r\n\r\n<b>Additional Comments:</b>\r\nNone.\r\n\r\n\r\n",
        "date": "09-04-2006",
        "review_id": 365
      },
      {
        "author": {
          "author_email": "perrine.paul@univ-rennes1.fr",
          "author_firstname": "Perrine",
          "author_id": 282,
          "author_lastname": "Paul"
        },
        "content": "<b>Summary:</b>\r\nAuthors presents a software framework whose purpose is to develop specific image-guided applications using multiple intra-operative imaging. The framework is based upon an extended open-source interfacing of the open-source OPenTracker library and an imager hardware interface GIHI, using 4 separate new modules. The framework was implemented to support multiple system interactions and visualization tasks, with a dynamic execution model. \r\n \r\n<b>Hypothesis:</b>\r\nThere is a need in image-guided therapy for software framework satisfying the following requirements: using multiple imaging instruments with proper functionality, portability, abstraction and speed. The fact of tracking multiple tools or getting multiple images at the same time in real-time is of course of great interest for image-guided surgery, in particular for augmented reality or augmented virtuality. \r\n\r\n<b>Evidence:</b>\r\nThe demonstration of the interest was based on the presentation of 5 clinical applications. However, the code is not yet available, it will be on the 19th of October. I was then not able to reproduce the presented results. The need of a framework allowing aplication as separate silos was justified by the regulatory requirements.\r\n\r\n<b>Open Science:</b>\r\nThe presented framework is is the spirit of open science, for 2 reasons: 1) it is based upon existing open-source libraries, and extended or interfaced them 2) The source code of the programs used in their experiments was not provided yet but it will be open source. It consists on an add-on to an existing open source library Open tracker and to a global framework library, the SIGN, interfacing other opens ource librairies.\r\n\r\n<b>Reproducibility:</b>\r\nNot available since no code was not provided\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe framework The SIGN is based upon (instead of duplicating) existing open-source efforts, as OpenTracker, VTK, KWWidgets, ITK, SPLOT , GIHI, Xerces and Ace. \r\n\r\n<b>Open Source Contributions:</b>\r\nNo code available. I was not able to compile the GIHI part, and the openTracker v1.3 is not available directly on the indicated link.\r\n\r\n<b>Code Quality:</b>\r\nThe developments was made in C, said to respect portability rules. But the code is not available. Nothing said about dart test or others.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe authors have shown the applicability to a large range of problem, by showin 5 different applications. The replay posibilities could be really interesting for pedagogical purposes, or to make some e-books for surgeon. \r\n\r\n<b>Suggestions for future work:</b>\r\n It will be of interest in the future first release to have the demonstrations application code, and an image simulator, or at least the replay. Moreover you could include to your software an aplication validation strategy, which could lead to both performance evaluation and validation of each developped application using the software. Most of time when developping an application using intraoperative imaging, you have not a wide access to the intraoperative imaging. Including simulators of different kind (for tools, images, etc...) is really important for rapid prototyping. \r\n\r\n<b>Requests for additional information from authors:</b>\r\nThe relation with the AMIGO operating room was not clear, since it was no more mentionned after its presentation. Figures are of interest for demonstrations of the workflow interest, I would like to have them bigger and with a detailed description. What is the black window in figure 4? It would be of interest to underline the differences with other available Image-guided surgery toolkits, as <A HREF=\\\\\\\"http://www.igstk.org/index.htm\\\\\\\">IGSTK</A>. What is reference (11)? Reference (9) and (10) are not cited in the text. \r\nCould you add a reference for MRML?\r\n\r\n<b>Additional Comments:</b>\r\nThe note was given following the reviewer\\\\\\'s guideline: detail of note: 1/2 Code not available but built upon open-source libraries+1/1 adress a real software-based need within the community+ 0.5/1 No material provided but concepts are well described + 1/1 all research projects in image-guided surgery would benefit of this work . Total: 3.5/5=> 4\r\n\r\n",
        "date": "08-10-2006",
        "review_id": 296
      },
      {
        "author": {
          "author_email": "pkaz@cs.jhu.edu",
          "author_firstname": "Peter",
          "author_id": 63,
          "author_lastname": "Kazanzides"
        },
        "content": "<b>Summary:</b>\r\nThis paper describes the Slicer Image Guided Navigator (SIGN) software being developed at BWH. It adds support for imaging and tracking systems to 3D Slicer (it seems), using the GIHI and OpenTracker open source libraries, respectively.\r\n \r\n<b>Hypothesis:</b>\r\nN/A\r\n\r\n<b>Evidence:</b>\r\nN/A\r\n\r\n<b>Open Science:</b>\r\nThe paper promises to adhere to the principles of open science, although the primary source code will not be available until October 19.\r\n\r\n<b>Reproducibility:</b>\r\nThe SIGN source code is not available for download. I downloaded the GIHI source code (SVN repository) but did not compile it. I tried to find OpenTracker V1.3 but it is not available from the specified web site, which lists V1.1.1 as the latest version. There is a note to contact the project administrator to get a developers version from SVN. I did not do this. Some of the documentation refers to OpenTracker V1.2 and later, so clearly the repository must contain more recent versions.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe SIGN projects uses a lot of open source software, including VTK, KWWIDGETS, ITK, OpenTracker, GIHI, XERCES, and ACE. It also uses the SPLOT package (extensions to OpenTracker), which I assume will be available as open source software. The relationship to 3D Slicer is not entirely clear. The paper states that the SIGN is designed to be \u00e2\u0080\u009chighly interoperable\u00e2\u0080\u009d with 3D Slicer. Can the SIGN run without Slicer? If so, it seems it would duplicate some of the functionality of Slicer. If not, Slicer should be added to the list of open source software.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe paper states that The SIGN will be released as open source on Oct 19. It also says that information will be given at www.ncigt.org. I only found a brief reference to the SIGN under the \u00e2\u0080\u009c3D Slicer Engineering\u00e2\u0080\u009d project.\r\n\r\n<b>Code Quality:</b>\r\nI looked at the GIHI source code, which is written in C for portability to older platforms. It is supported on Linux and Solaris at this time. The code quality seems fine, though one cannot call it \\\\\\\"modern\\\\\\\". Note, however, that The SIGN source code, which is the primary subject of this paper, may not have any similarities to GIHI.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe SIGN is an application framework and is therefore applicable to a large number of problems. 3D Slicer has been successfully applied to a number of applications, and it is reasonable to expect the SIGN (which seems to add intraoperative imaging and tracking support to 3D Slicer) to also be widely applicable.\r\n\r\n<b>Suggestions for future work:</b>\r\nObviously, finish the software and make it available as open source! Also, improve the operating system support (e.g., some components, such as GIHI, are limited at this time -- just Linux and Solaris).\r\n\r\n<b>Requests for additional information from authors:</b>\r\nThis paper presents a clear overview, but is short on technical details. Section 2.3 is especially brief and refers to (11) for comprehensive details. There actually is no reference 11 (maybe this should be 10?). I would have liked to see some explanation of the dynamic data structures. \r\n\r\nSome block diagrams, flowcharts, etc. describing the software would be a welcome addition. \r\n\r\n\r\n<b>Additional Comments:</b>\r\n\r\nFollowing are some minor typos:\r\n<ul>\r\n<li>Section 2.3 (noted above) and 2.4 refer to (11), but there is no reference with this number.</li>\r\n<li>The Medscan description says \u00e2\u0080\u009cin order to encoding all services\u00e2\u0080\u009d, which should be \u00e2\u0080\u009cin order to encode all services\u00e2\u0080\u009d.</li>\r\n<li>The section numbering seems to be off. I believe Sections 3.1, 4, 4.1, 4.2, 4.3 should have been 3.1, 3.2, 3.3, 3.4, 3.5.</li>\r\n<li>In Section 4.1 (Cardiac navigation), \u00e2\u0080\u009ccourse orientation\u00e2\u0080\u009d should be \u00e2\u0080\u009ccoarse orientation\u00e2\u0080\u009d.</li>\r\n<li>In Conclusions, \u00e2\u0080\u009cMy\u00e2\u0080\u009d should be \u00e2\u0080\u009cBy\u00e2\u0080\u009d.</li>\r\n</ul>\r\n\r\n\r\n\r\n",
        "date": "08-31-2006",
        "review_id": 348
      },
      {
        "author": {
          "author_email": "andinet.enqu@kitware.com",
          "author_firstname": "Andinet",
          "author_id": 68,
          "author_lastname": "Enquobahrie"
        },
        "content": "<b>Summary:</b>\r\n\r\nThe paper describes an open source software framework for building a multi-modality image guided therapy application. \r\n \r\n<b>Hypothesis:</b>\r\nThe designed software framework is useful for building image guided therapy applications.\r\n\r\n<b>Evidence:</b>\r\nFive applications developed using SIGN have been presented. However, source code was not provided for these applications. \r\n\r\n<b>Open Science:</b>\r\nThe software framework design and distribution scheme follows open science principles. The software framework uses heavily other open source toolkits such as OpenTracker, GIHI, VTK, ITK, KWWidgets, Xerces and Aceto. The source code for these toolkits are readily availbale. And, the source code for SIGN is scheduled to be released by Oct.19. \r\n\r\n<b>Reproducibility:</b>\r\nN/A\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe developers of SIGN have used open source toollkits such as OpenTracker, GIHI, VTK, ITK.\r\n\r\n<b>Open Source Contributions:</b>\r\nAuthors stated that the source code will be released by Oct 19th.\r\n\r\n<b>Code Quality:</b>\r\nN/A\r\n<b>Applicability to other problems:</b>\r\nSIGN is a useful software framework is useful to develop other image guide therapy applications.\r\n\r\n<b>Suggestions for future work:</b>\r\n\r\n<b>Requests for additional information from authors:</b>\r\nSafe software design principles and practicses employed in the SIGN software framework have not been discussed in the paper.\r\n\r\n<b>Additional Comments:</b>\r\n[This is a free-form field]\r\n\r\n",
        "date": "09-05-2006",
        "review_id": 373
      },
      {
        "author": {
          "author_email": "chent@cs.queensu.ca",
          "author_firstname": "Thomas kuiran",
          "author_id": 472,
          "author_lastname": "Chen"
        },
        "content": "<b>Summary:</b>\r\nThe paper demonstrated a new software framework (named \u00e2\u0080\u009cSlicer Image-Guided Navigator\u00e2\u0080\u009d or SIGN) for Image-Guided Therapy that aims to provide real-time intraoperative surgical navigation with dynamic visualization and interactions with multiple imaging and tracking devices, through a seamless integration of dynamic data structures (medical reality modeling language, or MRML). The software package was developed based on various open-source frameworks and will itself be open-source soon to be available to the public.\r\n \r\n<b>Hypothesis:</b>\r\nThe authors argue that newly emerging image-guided procedures and therapies have seen increasing use of multiple imaging modalities and tracking devices at the same time in the OR. I agree that new surgical navigation applications are therefore desired to seamlessly interact with different imaging and tracking systems through a virtually transparent interface (to the users) with significant portability and expendability. In addition, more and stricter regulatory requirements pose new challenges on academic software development for research tools in clinical treatments. \r\n\r\n<b>Evidence:</b>\r\nSeveral clinical-relevant applications were presented using the current development of SIGN. The software framework was itself very well established and clearly presented through detailed designs of various system components that handle different hardware and software interfacings (i.e. GIHI for the imager interfacing, OpenTracker for the tracker interfacing, and Hybrid for event and data handling). References to the open-source resources used were also adequately provided.\r\n\r\n<b>Open Science:</b>\r\nI think the proposed software framework is clearly designed with open-source development and distribution in mind. According to the paper, SIGN was developed primarily based on the open-source 3D Slicer framework and has extensively employed many other open-source frameworks (e.g., OpenTracker, GIHI, VTK, ITK, etc.) to develop its major system components (e.g., MedScan). The authors have also promised the release of SIGN\u00e2\u0080\u0099s original source codes on October 19th, 2006 to the open-source community. So it is evident to me that the proposed software framework will eventually benefit the public by contributing to the open-source community. \r\n\r\n<b>Reproducibility:</b>\r\nSince the source codes of SIGN will not be made available to general public until October 19th, 2006, I haven\u00e2\u0080\u0099t been able to reproduce the authors work as described in this paper. However, I was able to download and install the OpenTracker package from the link provided by the paper. I should point out that there is one small mistake in the paper regarding the latest version of OpenTracker (the paper mentioned that the latest version is v1.3, while on OpenTracker\u00e2\u0080\u0099s website, it states that v1.1.1 is its latest release). For GIHI, I kept getting a \u00e2\u0080\u009cconnection timeout\u00e2\u0080\u009d to the link suggested by the paper, so I have not been able to test it during the writing of this review. \r\n\r\n<b>Use of Open Source Software:</b>\r\nAn extensive use of the existing open-source software is evident in the development of SIGN. The framework was developed primarily based on the open-source 3D Slicer framework and has employed many other open-source frameworks (including OpenTracker, GIHI, VTK, ITK, KWWidgets, Xerces and Aceto) to develop its major system components.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe authors have promised the release of SIGN\u00e2\u0080\u0099s original source codes on October 19th, 2006 to the open-source community. No test is possible until then.\r\n\r\n<b>Code Quality:</b>\r\nThe authors have promised the release of SIGN\u00e2\u0080\u0099s original source codes on October 19th, 2006 to the open-source community. No examination of the code quality is possible until then.\r\n\r\n<b>Applicability to other problems:</b>\r\nMy understanding of the major strength of SIGN is in its ability to interface multiple imaging and tracking devices with seamless dynamic data integration and visualization. This framework could be extended to various existing image-guided surgical navigation systems that employ a broad range of imaging (e.g., CT, MRI, and US) and tracking (e.g., optical or magnetic) systems. In addition, the dynamic data encapsulation of SIGN (using MRML) may be applicable to many data management applications (not limited to medical applications) that wish to easily share, convert, and transfer data between different formats.\r\n\r\n<b>Suggestions for future work:</b>\r\nWas there a high-level design approach employed to outline the interrelationship between all the interfacing components in SIGN? Event handling for hybrid devices (devices of all kinds) in a generic interface is very attractive to many software engineering applications, but in general remains extremely complicated (essentially each device has its own protocol for communications). So in the future design of SIGN (and its extensions), a high-level design approach (e.g., Rational Rose or generic UML) is very helpful here to sort out all relationships between multiple system components at different interacting levels.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nPlease see the following additional comments.\r\n\r\n<b>Additional Comments:</b>\r\n1. In imaging hardware (Section 1.1), ultrasound (US) was not mentioned here as newly emerging imaging modalities. However, later on in the following sections, US was indicated apparently as one of the imagers in SIGN. \r\n\r\n2. In tracking devices (Section 1.2), the authors illustrate many types of tracking systems including their advantages and disadvantages. However, no single reference was given here. More references are necessary here.\r\n\r\n3. AMIGO (Section 1.4) was described as the context of the proposed framework (the ultimate application), however, there was no a word or two later in the paper briefing how, in a larger picture, SIGN is (or will be) adopted in AMIGO. Please provide a brief explanation of this link somewhere after SIGN is introduced.\r\n\r\n4. GIHI was written in C. Shouldn\\\\\\'t it consider using C++? Or at least a combination of C (for portability) and C++ (expandability)? Seems to me that GIHI requires many service/component extensions, either current or in the future. C is indeed portable and efficient but fairly poor at expandability, especially for a large system like SIGN that has multiple software components. \r\n\r\n5. Was there a specific design software used to design the overall structure of SIGN and its interactions with other system components (like OpenTracker and GIHI)? SIGN seems to be a very large, complicated, and distributed (multiple components acting in an asynchronous fashion) system employing a great amount of events and their handlers. It seems (at least to me) virtually impossible to design such a dynamic system efficiently and completely without the assistance of some professional design approaches (e.g, Rational Rose). \r\n\r\n6. In hybrid interfacing (Section 2.3), from a system-design point of view, why Terason is designed as a separate module that is parallel to MedScan? At a high level in the overall system, shouldn\\\\\\'t Terason be part of the GIHI library whose primary duty is to handle the interfacing with various imaging devices (which include US)? Please clarify.\r\n\r\n7. In the illustration of SIGN (Section 2.4 the last paragraph), I was a bit confused here: the tracker is presumably a monitoring device that traces the motion of the objects in real time. It is supposed to be a passive observer. So what does it mean that once connected to the data object in MRML tree, the tracker could move an object around the scene? Or maybe it was my incorrect interpretation? Please clarify a bit here.\r\n\r\n8. In the introduction of SIGN (Section 2.4), the authors claimed that \u00e2\u0080\u009cThe framework was designed to be highly interoperable with the 3D Slicer \u00e2\u0080\u00a6\u00e2\u0080\u009d. However, the exact relationship between SIGN and 3D Slicer still remains unclear to me even after reading through the entire paper. Was SIGN designed and developed primarily based on the 3D Slicer framework? Or they simply just share the same data structure protocol (using MRML)? Please clarify the term \u00e2\u0080\u009cinteroperable\u00e2\u0080\u009d in more details here.\r\n\r\n\r\n",
        "date": "08-17-2006",
        "review_id": 300
      },
      {
        "author": {
          "author_email": "pettri@medisin.uio.no",
          "author_firstname": "Petter",
          "author_id": 471,
          "author_lastname": "Risholm"
        },
        "content": "<b>Summary:</b>\r\nThe abundance of imaging devices, tracking devices and other electronic devices which image guided therapy relies on has resulted in many efforts to develop sofware frameworks which abstracts the inherent complexity of integrating such devices in image guided therapy software applications. Important requirements of such frameworks are portability, usability, synchronization, flexibility and speed. The authors describe a new framework which aims at supporting all of these requirements. Three main software components constitute the software framework. OpenTracker is a general data streaming components which can interface to such datasources as tracking devices, ECG devices and imaging sources. Another component handles interfacing to imaging hardware, GIHI, which can be used to extract tracking data from imaging devices where that is relevant, extract images in addition to provide a interface for controlling imaging parameters. The last component is VTK which is used for visualization purposes. XML is used to configure the framework and can be set up such that data can flow between the components in an almost seamless manner.\r\n \r\n<b>Hypothesis:</b>\r\nNot applicable.\r\n\r\n<b>Evidence:</b>\r\nA number of clinical examples are presented in the paper. However, the only example which is backed up by a reference to show its clinical relevance is the endoscopic navigation. \r\nI don\\\\\\\\\\\\\\'t really see how ITK is integrated in this framework.\r\n\r\n<b>Open Science:</b>\r\nMost of the source code is currently available such as OpenTracker and GIHI. The rest of the source code is set to be released in October. However, most of the source code which is due to be released are the parts which provides the interfaces between the various components. However, I didn\\\\\\\\\\\\\\'t quite understand whether the source code for the examples also will be released?\r\n\r\n<b>Reproducibility:</b>\r\nNot applicable since the source code is not publicly available.\r\n\r\n<b>Use of Open Source Software:</b>\r\nI don\\\\\\\\\\\\\\'t know. There is no section which discusses the licenses of the software components.\r\n\r\n<b>Open Source Contributions:</b>\r\n\r\n<b>Code Quality:</b>\r\n\r\n<b>Applicability to other problems:</b>\r\nThe framework should be applicable to many image guided applications due to its flexible nature.\r\n\r\n<b>Suggestions for future work:</b>\r\nI would definitely like to see how ITK is integrated in the framework. A seamless integration of ITK, or other image processing libraries, into image guided therapy frameworks is something I still haven\\\\\\\\\\\\\\'t witnessed.\r\n\r\nThe paper doesn\\\\\\\\\\\\\\'t discuss the advantages/disadvantages of The SIGN compared to other image guided therapy frameworks such as IGSTK, Julius etc.\r\n\r\n<b>Requests for additional information from authors:</b>\r\n\r\n<b>Additional Comments:</b>\r\nI\\\\\\\\\\\\\\'m looking to following the further development of the framework as it has many good things going for it. In particular, the interface to the popular slicer, VTK and ITK in addition to the novel hybrid data flow component.\r\n",
        "date": "08-14-2006",
        "review_id": 298
      }
    ],
    "revisions": [
      {
        "article": "bafybeib5b34jgaohgzgfox2x3grqzoi4l2busbz4byfcaxvow3onw63o6m",
        "citation_list": [
          {
            "doi": "10.1055/s-2008-1053478",
            "key": "ref1",
            "score": 96.42509,
            "unstructured": "Frameless neuronavigation in modern neurosugery+Minimally Invasive Neurosurgery+4+38+163+166+1995+U. Spetzger"
          },
          {
            "doi": "10.3109/10929080109146003",
            "key": "ref2",
            "score": 141.20992,
            "unstructured": "Spinal navigation in cervical fractures-a preliminary study on Judet-osteosynthesis of the axis+Computer Aided Surgery+3+6+170+175+2001+M. Arand+E. Hartwig+L. Kinzl+F. Gebhard"
          },
          {
            "key": "ref3",
            "score": 37.674717,
            "unstructured": "Virtual cystoscopy - a surgical planning and guidance tool+Arch Ital Urol Androl+1+78+23+24+2006+B. Braticevici+M. Onu+F. Bengus"
          },
          {
            "key": "ref4",
            "score": 28.836739,
            "unstructured": "Intra-operative Position Sensing and Tracking Devices, Proceeding of the First Joint CVRMed+62+64+1997+D.A. Simon"
          },
          {
            "key": "ref5",
            "score": 57.79798,
            "unstructured": "Development of a Navigation System for Neurofiberscopic Surgery+Symposium of the International Brain Mapping and Intraoperative Surgical Planning Society+2005+L. J. Wada+F. Goumnerova+Jolesz"
          },
          {
            "doi": "10.1117/12.706079",
            "key": "ref6",
            "score": 101.403656,
            "unstructured": ", Multi-Modal Event Streams for Virtual Reality, Multimedia Computing+2007+D. J. von Spiczak+CR Schmalstieg+E. Burghart+Samset"
          }
        ],
        "dapp": null,
        "dataset": null,
        "doi": null,
        "handle": "1926/207",
        "source_code": null,
        "source_code_git_ref": null
      }
    ],
    "source_code_git_repo": null,
    "submitted_by_author": {
      "author_email": "samset@bwh.harvard.edu",
      "author_firstname": "Eigil",
      "author_fullname": "Samset, Eigil",
      "author_id": 447,
      "author_institution": "Brigham and Women\\'s Hospital",
      "author_lastname": "Samset"
    },
    "tags": [
      "Software",
      "Image Guided Therapy"
    ],
    "title": "The SIGN: A dynamic and extensible software framework for Image-Guided Therapy"
  }
}